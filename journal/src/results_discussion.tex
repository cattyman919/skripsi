\section{Results and Discussion} \label{sec:results_discussion}
This section presents the results of the security analysis and performance measurements, followed by a discussion of the findings.

\subsection{Security Analysis Results}
The effectiveness of VxLang virtualization was evaluated through static and dynamic analysis attempts to understand and bypass the authentication logic in the case study applications.

\subsubsection{Static Analysis (Ghidra)}
\begin{itemize}
	\item \textbf{Non-Virtualized Binaries:} Analysis was straightforward. Relevant strings (e.g., "Authentication Failed", hardcoded "seno", "rahman") were easily located in the `.rdata` or `.text` sections. Cross-references led directly to the authentication functions. Disassembly clearly showed standard comparison instructions (\texttt{memcmp}, \texttt{strcmp}, or C++ string comparison operators) followed by conditional jumps (\texttt{JNZ}, \texttt{JE}) controlling the flow based on the comparison result (See example Listing \ref{lst:asm_static_nonvirt_snippet} and context in Appendix Listing \ref{lst:asm_static_nonvirt_full}). For cloud variants, the call to the request function and the subsequent check on its return value were identifiable (Listing \ref{lst:asm_static_cloud_snippet}, Appendix \ref{lst:asm_static_cloud_full}). Static patching of the conditional jump instruction to force the "authorized" path was trivial in all non-virtualized cases.
	\item \textbf{Virtualized Binaries:} Static analysis proved significantly more challenging.
	      \begin{itemize}
		      \item \textit{Instruction Recognition Failure:} Ghidra consistently failed to recognize standard x86-64 instructions within the virtualized sections, reporting large blocks of unknown opcodes or '???' entries. Analysis summaries showed a drastic reduction (often to zero) in the count of recognized instructions and functions compared to the originals (e.g., Fig. \ref{fig:ghidra_summary_qt_journal} vs. Fig. \ref{fig:ghidra_summary_qt_vm_journal}).
		      \item \textit{Data Obfuscation:} Critical strings like "Authentication Failed" or hardcoded credentials were no longer present as plain text in the binary, preventing simple string searches from locating the relevant code sections. Symbol information was also heavily stripped.
		      \item \textit{Control Flow Obscurity:} The clear structure of conditional checks and jumps seen in the original code was replaced by opaque sequences of seemingly unrelated or unknown instructions, making it impossible to identify the core authentication logic or the specific conditional jump to patch statically. The control flow graph became fragmented and uninformative within the virtualized regions.
	      \end{itemize}
	      Static bypass attempts were unsuccessful due to the inability to locate and understand the relevant control flow logic.
\end{itemize}

% --- Ghidra Summary Figures (Journal) ---
\begin{figure}[!t]
	\centering
	\includegraphics[width=0.9\linewidth]{../assets/pics/app_qt_summary_result.jpeg}
	\caption{Ghidra Analysis Summary for \texttt{app\_qt.exe} (Non-Virtualized).}
	\label{fig:ghidra_summary_qt_journal}
\end{figure}

\begin{figure}[!t]
	\centering
	\includegraphics[width=0.9\linewidth]{../assets/pics/app_qt_vm_summary_result.jpeg}
	\caption{Ghidra Analysis Summary for \texttt{app\_qt\_vm.exe} (Virtualized, showing data for app\_qt\_vxm.exe structure).}
	\label{fig:ghidra_summary_qt_vm_journal}
\end{figure}


\subsubsection{Dynamic Analysis (x64dbg)}
\begin{itemize}
	\item \textbf{Non-Virtualized Binaries:} Dynamic analysis corroborated static findings. Setting breakpoints based on string references or near conditional jumps identified statically was effective. Stepping through the code clearly showed the comparison logic and the conditional jump execution. Runtime patching of the jump instruction in x64dbg successfully bypassed authentication (See example Listing \ref{lst:asm_dynamic_nonvirt_snippet} and context in Appendix Listing \ref{lst:asm_dynamic_nonvirt_full}).
	\item \textbf{Virtualized Binaries:} Dynamic analysis faced significant hurdles.
	      \begin{itemize}
		      \item \textit{String Searching Failure:} Searching for relevant strings in memory during runtime often failed, similar to static analysis.
		      \item \textit{Execution Flow Tracking Difficulty:} Stepping through the virtualized code sections was extremely difficult. The instruction pointer (RIP) often appeared to loop within small blocks or jump to seemingly random locations, consistent with execution being handled by the VM interpreter rather than direct native execution (See Listings \ref{lst:asm_dynamic_io_nonvirt_snippet} vs. \ref{lst:asm_dynamic_io_virt_snippet}, Appendix \ref{lst:asm_dynamic_io_comparison_full}). Standard debugging techniques like setting breakpoints based on expected native instructions became unreliable.
		      \item \textit{State Obfuscation:} Understanding the program's state (relevant variable values, comparison results) was hindered because the actual logic was executed within the VM's context, which was not directly visible or interpretable through the debugger's view of native registers and memory.
	      \end{itemize}
	      Dynamic bypass attempts by patching suspected native jump instructions (if any could be identified near the VM entry/exit) were unsuccessful, as the core logic resided within the VM's execution loop.
\end{itemize}

These results strongly indicate that VxLang's code virtualization effectively hinders both static and dynamic reverse engineering attempts using standard tools and techniques.

\subsubsection{Analysis of Lilith RAT}
Static and dynamic analysis were also performed on the Lilith RAT client (original vs. virtualized). Findings mirrored those from the authentication case studies:
\begin{itemize}
	\item \textbf{Non-Virtualized:} Analysis was feasible. Strings related to commands and functionality were identifiable. Control flow for network communication and command handling could be traced using Ghidra and x64dbg, allowing potential understanding of its mechanisms (e.g., keylogging, remote execution).
	\item \textbf{Virtualized:} Analysis difficulty increased significantly. Ghidra failed to properly disassemble virtualized sections, showing numerous '???' entries and obscuring the logic. Dynamic tracing in x64dbg was severely hampered by the VM execution, making it hard to follow command processing or data flow.
	\item \textbf{Functional Integrity:} Importantly, functional testing confirmed that the virtualized Lilith client remained fully operational, successfully connecting to the server and executing core RAT commands, despite the code transformation.
\end{itemize}
This indicates VxLang's virtualization hinders analysis even for complex, potentially malicious software, without necessarily breaking its intended functionality.

\subsection{Performance and Size Overhead Results}

\subsubsection{Execution Time Overhead}
The performance impact was measured using QuickSort and AES benchmarks.

\begin{itemize}
	\item \textbf{QuickSort:} As shown in Table \ref{tab:quick_sort_performance_journal} and Fig. \ref{fig:quick_sort_performance_journal}, virtualization introduced substantial execution time overhead. The overhead increased with data size, ranging from approximately 27,300\% for 100 elements (0.01 ms to 2.74 ms) to about 15,150\% for 1,000,000 elements (218.32 ms to 33,292.91 ms). This indicates a significant constant overhead plus a scaling factor imposed by the VM's interpretation loop for the recursive sorting function.
	      \begin{table}[!t]
		      \centering
		      \caption{Quick Sort Execution Time Results (ms)}
		      \label{tab:quick_sort_performance_journal}
		      \resizebox{\columnwidth}{!}{%
			      \begin{tabular}{@{}lrrrr@{}}
				      \toprule
				      \multirow{2}{*}{\textbf{Array Size}} & \multicolumn{2}{c}{\textbf{Non-Virtualized}} & \multicolumn{2}{c}{\textbf{Virtualized}}                                        \\
				      \cmidrule(lr){2-3} \cmidrule(lr){4-5}
				                                           & \textbf{Avg Time}                            & \textbf{Std Dev}                         & \textbf{Avg Time} & \textbf{Std Dev} \\
				      \midrule
				      100                                  & 0.01                                         & 0.00                                     & 2.74              & 0.38             \\
				      1,000                                & 0.08                                         & 0.00                                     & 27.35             & 1.25             \\
				      5,000                                & 0.54                                         & 0.05                                     & 144.44            & 8.25             \\
				      10,000                               & 1.24                                         & 0.08                                     & 295.77            & 13.68            \\
				      50,000                               & 6.98                                         & 0.51                                     & 1,556.15          & 122.81           \\
				      100,000                              & 15.12                                        & 1.26                                     & 3,080.30          & 303.02           \\
				      500,000                              & 104.44                                       & 7.30                                     & 14,298.92         & 374.98           \\
				      1,000,000                            & 218.32                                       & 8.10                                     & 33,292.91         & 4,342.93         \\
				      \bottomrule
			      \end{tabular}
		      } % End resizebox
	      \end{table}

	      \begin{figure}[!t]
		      \centering
		      \begin{tikzpicture}
			      \begin{axis}[
					      width=0.95\columnwidth,
					      height=6cm,
					      xlabel={Array Size},
					      ylabel={Avg. Exec. Time (ms)},
					      xmode=log,
					      log basis x={10},
					      ymode=log,
					      log basis y={10},
					      legend pos=north west,
					      grid=major,
					      tick label style={font=\tiny},
					      label style={font=\small},
					      legend style={font=\tiny}
				      ]
				      \addplot coordinates {
						      (100, 0.01)
						      (1000, 0.08)
						      (5000, 0.54)
						      (10000, 1.24)
						      (50000, 6.98)
						      (100000, 15.12)
						      (500000, 104.44)
						      (1000000, 218.32)
					      };
				      \addlegendentry{Non-Virtualized};

				      \addplot coordinates {
						      (100, 2.74)
						      (1000, 27.35)
						      (5000, 144.44)
						      (10000, 295.77)
						      (50000, 1556.15)
						      (100000, 3080.30)
						      (500000, 14298.92)
						      (1000000, 33292.91)
					      };
				      \addlegendentry{Virtualized};
			      \end{axis}
		      \end{tikzpicture}
		      \caption{Quick Sort Execution Time Comparison (Log-Log Scale).}
		      \label{fig:quick_sort_performance_journal}
	      \end{figure}


	\item \textbf{AES Encryption:} Table \ref{tab:aes_performance_journal} shows that the total time for encrypting 976MB of data increased by approximately 396.7\% (1878.52 ms to 9330.73 ms), and decryption time increased by about 562.9\% (1304.75 ms to 8649.74 ms). Consequently, the combined throughput dropped dramatically from 634.16 MB/s to 108.78 MB/s (an 82.8\% reduction). This confirms a significant overhead for cryptographic operations.
	      \begin{table}[!t]
		      \centering
		      \caption{AES-256-CBC Performance Results (976MB Data)}
		      \label{tab:aes_performance_journal}
		      \resizebox{\columnwidth}{!}{%
			      \begin{tabular}{@{}lrr@{}}
				      \toprule
				      \textbf{Metric}              & \textbf{Non-Virtualized} & \textbf{Virtualized} \\
				      \midrule
				      Total Encryption Time (ms)   & 1,878.52                 & 9,330.73             \\
				      Total Decryption Time (ms)   & 1,304.75                 & 8,649.74             \\
				      Avg. Encrypt Time/Block (ms) & 0.00188                  & 0.00933              \\
				      Avg. Decrypt Time/Block (ms) & 0.00130                  & 0.00865              \\
				      Encrypt Throughput (MB/s)    & 519.86                   & 104.66               \\
				      Decrypt Throughput (MB/s)    & 748.46                   & 112.90               \\
				      Combined Throughput (MB/s)   & 634.16                   & 108.78               \\
				      \bottomrule
			      \end{tabular}
		      } % End resizebox
	      \end{table}

\end{itemize}

\subsubsection{File Size Overhead}
Table \ref{tab:file_size_journal} shows a consistent increase in executable file size after virtualization. For smaller console/benchmark programs (\texttt{quick\_sort}, \texttt{encryption}, \texttt{console}, \texttt{Lilith\_Client}), the size increased by over 15-18 times (from ~80-110 KB to ~1.5-1.6 MB). For larger GUI applications (\texttt{app\_imgui} from 1,675 KB to 2,330 KB; \texttt{app\_qt} from 122 KB to 1,578 KB) and the benchmark with embedded data (\texttt{size} from 97,771 KB to 112,324 KB), the relative increase was smaller but still significant. This overhead is primarily attributed to the inclusion of the VxLang VM runtime and the bytecode representation of the original code.
\begin{table}[H]
	\centering
	\caption{Executable File Size Comparison (KB)}
	\label{tab:file_size_journal}
	\resizebox{\columnwidth}{!}{
		\begin{tabular}{@{}lrr@{}}
			\toprule
			\textbf{Program}  & \textbf{Non-Virtualized (KB)} & \textbf{Virtualized (KB)} \\
			\midrule
			quick\_sort       & 98                            & 1,537                     \\
			encryption        & 110                           & 1,507                     \\
			size              & 97,771                        & 112,324                   \\
			console           & 92                            & 1,577                     \\
			console\_cloud    & 281                           & 1,695                     \\
			app\_imgui        & 1,675                         & 2,330                     \\
			app\_imgui\_cloud & 1,860                         & 2,418                     \\
			app\_qt           & 122                           & 1,578                     \\
			app\_qt\_cloud    & 315                           & 1,671                     \\
			Lilith\_Client    & 84                            & 1,554                     \\
			\bottomrule
		\end{tabular}
	}
\end{table}

\subsection{VirusTotal Detection Analysis}
To assess the impact of VxLang virtualization on automated malware detection, both the original and virtualized Lilith RAT client executables  were submitted to VirusTotal.

\begin{itemize}
	\item \textbf{Non-Virtualized Lilith:} Detected by \textbf{22 out of 72} engines. Analysis revealed specific threat labels like "trojan.lilithrat/keylogger" and family labels including "lilithrat" and "keylogger". Detections often included specific names like "Backdoor:Win64/LilithRat.GA!MTB" or "Trojan[Backdoor]/Win64.LilithRAT".
	\item \textbf{Virtualized Lilith:} Detected by \textbf{18 out of 72} engines, showing a decrease in detection rate. The popular threat label became a generic "trojan", and specific family labels disappeared. Detection signatures shifted towards generic malware, heuristic-based flags, AI/ML detections, or packed/protected software warnings (e.g., "Trojan:Win32/Wacatac.C!ml", "Static AI - Suspicious PE", "ML.Attribute.HighConfidence", "RiskWare[Packed]/Win32.VMProtect.a").
\end{itemize}
These results suggest that VxLang virtualization effectively obfuscates static signatures used by many traditional antivirus engines, forcing reliance on less specific heuristic or AI-based methods, and potentially evading detection by some vendors altogether.

\subsection{Discussion}
The experimental results clearly demonstrate the core trade-off inherent in using VxLang's code virtualization.

\textbf{Security Enhancement and Detection Evasion:} VxLang provides a substantial barrier against common reverse engineering techniques, applicable even to complex software like the Lilith RAT while preserving its functionality. The transformation into interpreted bytecode neutralizes standard static analysis tools (Ghidra) and significantly complicates dynamic analysis (x64dbg). Furthermore, the VirusTotal analysis indicates that this obfuscation extends to automated malware detection; VxLang effectively hinders signature-based detection, reduces overall detection rates, and forces AV engines towards more generic or heuristic approaches. This capability to evade specific detection signatures adds another layer to its protective potential, aligning with the expected benefits of advanced obfuscation \cite{Ore06, Sal18, Rou13}.

\textbf{Performance Cost:} The security and evasion benefits come at a steep price in terms of performance. The interpretation overhead significantly slows down virtualized code, especially for computationally intensive tasks (QuickSort overhead of ~15,000\% for 1M elements; AES throughput reduction of ~83\%), potentially rendering indiscriminate application impractical due to severe speed degradation.

\textbf{Size Increase:} The considerable increase in file size (e.g., 15-18x for small applications), mainly due to the embedded VM runtime, is another factor, particularly relevant for smaller applications or distribution constraints.

\textbf{Practical Implications:} VxLang appears potent for protecting highly sensitive code where security and potentially detection evasion are paramount, and the performance impact on those specific segments is acceptable (e.g., anti-tamper, licensing, core IP). The Lilith case shows it can protect complex logic without breaking it. However, the severe performance cost necessitates a strategic, selective application, targeting only critical sections. The VirusTotal results also imply that while detection is hindered, it's not eliminated, especially by heuristic/AI methods or tools flagging the protection layer itself. The choice between hardcoded and cloud-based authentication showed that protecting client-side logic handling the *result* of validation remains crucial, reinforcing the need for techniques like virtualization on critical checks, regardless of where primary authentication occurs.
